## Comparison of Performance and Best Practices of Data Imputation Techniques

### Abstract ðŸ“‘

GAN training can be tricky and very sensitive. It is still an active research domain to achieve a stable and consistent training method for GANs.
This work particularly focuses on DC-GANs and the best practices that can be followed for stable GAN training. The manuscript particularly dives into the hyperparameters and architectural choices to optimize the min-max game for a stable nash equilibrium. Common pitfalls and challenges in training are discussed along with possible solutions to overcome the same. A comprehensive guide to stable and consistent GAN training is the main focus of this work. However, we also explore whether one can control the generative output by achieving disentanglement in DC-GANs. Finally, compare various architectures and designs of DC-GANs to arrive at a recommendable design choice for a stable GAN training. 
